{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanSong19/PALS0039-Introduction-to-Deep-Learning-for-Speech-and-Language-Processing-/blob/main/PALS0039_Ex_3_1_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIFXp68GRrpz"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "#Exercise 3.1 Keras practice\n",
        "\n",
        "In this exercise we use Keras to build and train a small 4-2-4 [autoencoder](https://en.wikipedia.org/wiki/Autoencoder)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJSnFLaaR0BS"
      },
      "source": [
        "(a) The following code block constructs a simple network with 4 inputs, one hidden layer (with 2 nodes), and 4 outputs. Run the code and add comments to explain what each line does. Is this a regression or classification model? What are the ranges of output values the model is capable of producing?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "## if it is only import tensorflow, then, when I use later it has to by a=tensor.flow.keras.models.Sequential() but when I import Sequential from \n",
        "## from tensorflow.keras.modls import Sequential, then I can just call it like a=Sequential()\n",
        "\n",
        "#it initiate a neural network: I have a model and it is an empty neural network\n",
        "#sequential is a multi layer neural network\n",
        "model = Sequential()\n",
        "\n",
        "#no need of the input layer because I only need the input form not layer. \n",
        "#model.add : adds a layer to the model\n",
        "#the first layer is a dense: danse is a fully connected to all the previous input with weights\n",
        "#the first parameter is the number of unit, here, there are 2 units, The number of unit can be changed depending on the task/ goal fo the model\n",
        "#input shape: store the weights (only need it in the first layer and from the second later, it will be automatic)\n",
        "# input_shape(4,) mans it is a single vector, 4 means that there are 4 features (inputs)\n",
        "model.add(Dense(2, activation='sigmoid', input_shape=(4,), name=\"hidden_layer\"))\n",
        "\n",
        "#if I want more hidden layer, I can add more and more\n",
        "#model.add(Dense(4, activation='sigmoid', name=\"output_layer2\"))\n",
        "\n",
        "model.add(Dense(4, activation='sigmoid', name=\"output_layer\"))\n",
        "\n",
        "#Reconstruc obtimizer. Stochaic gradient descent. I can choose, leanring rate=0.1 is very fast\n",
        "#momentum: taking the precious step into account\n",
        "sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
        "\n",
        "#.compile is that I finished build and secure the model and I am ready to train the model\n",
        "model.compile(loss='mse', optimizer=sgd)\n",
        "# output shape (None,2), None=empty because waiting for the input\n",
        "# first node has 10 parameter (first layer has 2 input that is 4(input_shape)*2(2 output nodes) +2 biases)\n",
        "# the second node has 12 parameter (2*4+4 (4 biases of the second layer))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "'''\n",
        "the model looks like this\n",
        "\n",
        "input hidden output\n",
        "x.             x\n",
        "x.      x.     x\n",
        "x.      x.     x\n",
        "x              x\n",
        "\n",
        "This model reduces the dimension. 4 input to 2 in the hidden layer. why? \n",
        "maybe 4 features are too many and see if we can reduce dimensions.\n",
        "auto encoder is often used to reduce the #of features automatically.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiSCJlqz7Lcl",
        "outputId": "aea68464-44dd-4859-e1c8-9fb29332a60b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden_layer (Dense)        (None, 2)                 10        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 4)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22\n",
            "Trainable params: 22\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBwByTZaRq7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530c4d2b-1798-4388-d579-83e5c2e6a823"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Instructions to build the Keras model\n",
        "def build_model():\n",
        "  # Variable \"model\" is of class tensorflow.keras.models.Sequential\n",
        "  # That class represents neural networks, where one layer is processed after another. (This represents almost all neural networks, but look for skip connections and the ResNet if interested in more powerful architectures. They are used in our application, for example the WaveNet: https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)\n",
        "  # The neural network is empty at this point.\n",
        "  model = Sequential()\n",
        "  # Class tensorflow.keras.models.Sequential has a function \"add\" that adds a layer to the network\n",
        "  # We add the first layer. It is of type Dense, the typical layer in a MLP that is fully connected to the previous layer\n",
        "  # It has two units. Their activation functions are sigmoids.\n",
        "  # Because it is the first layer we have to specify the number of inputs. Four inputs for our two nodes lead to 4x2=8 weights, plus 2 bias weights.\n",
        "  # The name is useful for bigger networks or when we want to copy parts of the network.\n",
        "  model.add(Dense(2, activation='sigmoid', input_shape=(4,), name=\"hidden_layer\"))\n",
        "  # We add another layers with 4 nodes. The model already knows that this layer receives inputs from the two nodes of the previous layer.\n",
        "  # This layer will have 2x4 = 8 weights plus 4 bias weights.\n",
        "  model.add(Dense(4, activation='sigmoid', name=\"output_layer\"))\n",
        "  # We create an object for the optimizer, from the class SGD, and we name it \"sgd\". We give it bigger parameters than the defaul to train faster.\n",
        "  sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
        "  # The \"compile()\" of class tensorflow.keras.models.Sequential actually creates the model and we can start training.\n",
        "  # We specify the loss function to be the mean squared error and the optimizer.\n",
        "  # If we wanted to use an optimizer with its default values, we could simply specify it by name, for example optimizer='Adam'\n",
        "  model.compile(loss='mse', optimizer=sgd)\n",
        "  return model\n",
        "\n",
        "# Input data\n",
        "#I can have more input data by adding [x,x,x,x] at the end\n",
        "X = np.array([[1.0, 0.0, 0.0, 0.0],\n",
        "              [0.0, 1.0, 0.0, 0.0],\n",
        "              [0.0, 0.0, 1.0, 0.0],\n",
        "              [0.0, 0.0, 0.0, 1.0]])\n",
        "# Output data\n",
        "Y = X.copy()\n",
        "\n",
        "print(\"Input\\n\", X)\n",
        "print(\"Output\\n\", Y)\n",
        "\n",
        "#(a)\n",
        "# - Regression\n",
        "# - [0.0, 1.0] -- Sigmoid activation function"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input\n",
            " [[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "Output\n",
            " [[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5b20_6ArIlz"
      },
      "source": [
        "(b) Complete the code block below to train the model on the data defined above using the model's [`fit` method](https://keras.io/api/models/model_training_apis/#fit-method). Use the specification in the comments to set up the training parameters accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XepltgxvrK74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "aebfc619-4123-4846-96ea-f011db0c180d"
      },
      "source": [
        "# Build the model using the earlier function\n",
        "model = build_model()\n",
        "\n",
        "# Train the model using 1000 iterations through the dataset with weight updates after processing each individual sample:\n",
        "#(b)\n",
        "# vector is low alphabet and metrix is Cap letters\n",
        "#interation is one update of weight. Epochs is how often do I run the model\n",
        "\n",
        "training_info = model.fit(X, Y, epochs=1000, batch_size=1, verbose=0)\n",
        "\n",
        "# Plot the value of the loss function over training\n",
        "plt.plot(training_info.history['loss'])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Print the predicted output values for the training data\n",
        "print(\"Predicted:\", np.around(model.predict(X), decimals=2), sep=\"\\n\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 166ms/step\n",
            "Predicted:\n",
            "[[0.9  0.   0.05 0.05]\n",
            " [0.   0.91 0.07 0.07]\n",
            " [0.08 0.06 0.92 0.  ]\n",
            " [0.09 0.06 0.   0.92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayV_VSD1sIAu"
      },
      "source": [
        "The following code block displays the network configuration, including number of parameters (weights) that were estimated during training. Furthermore it displays the actual weights and biases of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk83yfrqbfd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7875247-87c5-4e80-a319-96c948d5057a"
      },
      "source": [
        "# Print a summary of the structure of the model\n",
        "model.summary()\n",
        "\n",
        "# Get the weights as a numpy array\n",
        "weights=model.get_weights()\n",
        "\n",
        "# Print the weights for the different layers\n",
        "# odd numbers are biases \n",
        "print()\n",
        "print(\"hidden-to-input:\", weights[0], \"\", sep=\"\\n\")\n",
        "#weight 1 is bias of the first output\n",
        "print(\"hidden-bias:\", weights[1], \"\", sep=\"\\n\")\n",
        "#weight2 is the weight from the previous output\n",
        "print(\"output-to-hidden:\", weights[2], \"\", sep=\"\\n\")\n",
        "#bias of the second layer\n",
        "print(\"output-bias:\", weights[3], \"\", sep=\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden_layer (Dense)        (None, 2)                 10        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 4)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22\n",
            "Trainable params: 22\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "hidden-to-input:\n",
            "[[ 4.095022   3.8660212]\n",
            " [-3.352769  -3.411203 ]\n",
            " [-3.4864464  3.4757807]\n",
            " [ 3.2428386 -3.5654728]]\n",
            "\n",
            "hidden-bias:\n",
            "[-0.37336275 -0.28939566]\n",
            "\n",
            "output-to-hidden:\n",
            "[[ 4.7086515 -5.6291575 -5.7548356  5.465237 ]\n",
            " [ 4.6164346 -5.5515137  5.49278   -5.7941384]]\n",
            "\n",
            "output-bias:\n",
            "[-6.914473   2.605479  -2.646178  -2.5879366]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPI2e5SnkDbM"
      },
      "source": [
        "(c) Using the sigmoid function defined below, write some code to manually calculate the outputs of the network using the `weights` and `X` as input. **OR** Explain how the weights and biases are used to calculate the networks outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1rCOKjtkH5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14d6223-bace-4d21-af59-0bcdc401cfd7"
      },
      "source": [
        "# definition of the signoid activation function\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "  \n",
        "#(c)\n",
        "#For each training sample:\n",
        "for i in range(4):\n",
        "  # Get the input\n",
        "  input = X[i]\n",
        "  # Calculate the hidden layer activations\n",
        "  hidden_activations = sigmoid(np.matmul(input, weights[0]) + weights[1])\n",
        "  # Get the output layer activations\n",
        "  output_activations = sigmoid(np.matmul(hidden_activations, weights[2]) + weights[3])\n",
        "  # Print the input, hidden and output values for this sample\n",
        "  print(input, np.around(hidden_activations, decimals=2), np.around(output_activations, decimals=2), sep=\"\\t\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0.]\t[0.03 0.97]\t[0.92 0.09 0.   0.06]\n",
            "[0. 1. 0. 0.]\t[0.98 0.96]\t[0.06 0.89 0.05 0.  ]\n",
            "[0. 0. 1. 0.]\t[0.91 0.02]\t[0.   0.09 0.92 0.05]\n",
            "[0. 0. 0. 1.]\t[0.01 0.04]\t[0.07 0.   0.07 0.91]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (d) What are autoencoders useful for?"
      ],
      "metadata": {
        "id": "_uek-sS6hsM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(d)\n",
        "#https://en.wikipedia.org/wiki/Autoencoder#Applications"
      ],
      "metadata": {
        "id": "S_W0Ttu1h04c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}